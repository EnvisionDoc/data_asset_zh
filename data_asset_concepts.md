# 术语

本文介绍数据资产管理涉及的术语。

## 数据存储策略相关术语

数据存储策略相关的专有名词及术语的定义和解释如下，方便你理解相关概念并制定适用的数据存储策略。

### Storage group

存储分组，支持将不同项目或不同领域的存储需求进行不同的配置，比如风领域和光领域的数据存储可以分开配置。

### Storage type

存储类型，支持将不同类型的数据（AI原始数据，AI分钟级归一化数据，DI数据，通用数据）进行分别存储，并可通过调用不同的API接口查询存储的数据。

### Storage time

数据保留时长，目前支持的存储时长为1个月、3个月、6个月、1年、2年、3年、5年、10年、15年、20年。



## 流数据分析相关术语

流数据分析相关的专有名词及术语的定义和解释如下，方便你理解相关概念并使用流数据处理功能来开发流数据处理任务。

### Stream data

一般来说，数据的生成可以看作是一系列离散事件。在时间轴上绘制这些离散事件时，将形成事件流或数据流。流数据由这些连续的事件流组成。

离线数据和流数据通常都被作为日志发送。与传统的离线数据不同，流数据是由许多数据源连续生成的。但是，流数据的数据量通常小于离线数据的量。

流数据的常见数据源是连接到数据中心的设备、设备的遥测数据、以及移动应用或Web应用程序生成的日志文件。

### Stream analytics

流数据分析一般具有如下特征：

- 无界的实时数据流：流式计算引擎需要处理的数据是实时和无界的。数据流按时间顺序由流式计算服务订阅和消费。数据是连续生成的，所以数据流被连续地集成到流式计算系统中。例如，网站的访问日志是一种流数据，只要网站在线，日志就连续记录数据。因此，流数据始终是实时的和无边界的。
- 连续高效的计算：流数据分析的计算模式是“事件触发”式的。触发器是前面提到的无边界流数据。每当新的流数据发送到流式计算系统，系统立即启动并执行计算任务。因此，流式计算是一个连续的过程，并且很高效。
- 实时流数据集成：流数据触发流式计算之后，计算结果直接记录到目标数据存储中。例如，计算后的结果可以被直接写入关系数据库（RDS）中，用以生成报表。因此，流数据的计算结果被连续记录到目标数据存储器中。

### Data type

EnOS流处理引擎提供特有的数据处理模板，支持多种数据类型。测点的数据类型是在创建设备模型时定义的。

### Data processing strategy

对同一设备模型数据的统一窗口聚合方案，由输入点、输出点、阈值范围、插值策略、算法、和窗口大小组成。

### Event time

流数据聚合处理通常是基于事件时间的，即事件实际发生的时间。更准确地说，每个事件都有一个对应的时间戳，时间戳是数据记录的一部分。事件时间实际上是一个时间戳。当事件时间用于定义时间窗时，流处理引擎可以处理乱序事件流以及变化的时间偏差，并根据事件实际发生的时间计算出有意义的结果。

### Time window

EnOS流数据处理引擎是基于时间窗口（微批量模型）的流计算引擎，以指定的窗口大小（批量大小的间隔）来处理数据。时间窗口大小可以确定流计算任务获取数据的频率，即在一次窗口分析中需要处理的数据量。

### Tumbling window

滚动窗口将每个元素分配给指定窗口大小的窗口。这种窗口有固定的窗口大小并且不重叠。例如，如果指定一个大小为5分钟的翻滚窗口，将评估当前窗口，并且每5分钟启动一个新窗口，如下图所示。

.. image:: media/window_type.png

### Window latency

若窗口不设置延迟，当下一个窗口产生时，正常情况下前一个窗口已完成计算，可进行销毁。但是实际情况下，受制于各种因素比如资产故障、传输效率等，资产数据可能会延时上送。这种情况下可允许窗口设置继续停留的时间，即延迟销毁的时间。在延迟时间内到达的属于前一个窗口的数据会被纳入前一个窗口进行再次计算，超出延迟时间到达的窗口数据会被直接丢弃。如下图所示：Window2的窗口大小是5min，此窗口应包含所有时间戳位于11:00-11:05这个时间区间内的元素，不设置窗口延迟时，Window2窗口将会在11:05时刻销毁，Data1、Data2会被丢弃，当设置窗口延迟为5min时，Data1会参与Window2窗口的计算，Data2会被丢弃。

.. image:: media/latency_setting.png



## 数据订阅相关术语

数据订阅相关的专有名词及术语的定义和解释如下，方便你理解相关概念并使用数据订阅功能进行应用开发。

### Kafka

Kafka是一个分布式的消息系统，只需要把数据传给Kafka，在需要的时候可直接读取，实现异步非IO阻塞。

### Topic

消息主题，一级消息类型，通过 Topic 对消息流进行分类和存储。

### Partition

分区，每个Topic可以按特定的分区逻辑分区。Partition的数据决定了一个Topic可以同时支持的进程（用户）数量（如果一个Topic的Partition为3，那么Producer只能同时起3个进程写入，Consumer同时有3个进程进行消费，如果启动的数量超过3个则会一直等待）。

### Data producer

数据生产者，也称为消息发布者，生产并发送消息。

### Data consumer

数据消费者，也称为消息订阅者，接收并消费消息。

### Consumer instance

Consumer 的一个对象实例，不同的 Consumer 实例可以运行在不同进程内或者不同机器上。一个 Consumer 实例内配置线程池消费消息。

### Consumer group

一类 Consumer 的标识，这类 Consumer 通常接收并消费一类消息，且消费逻辑一致。

### Group consumption

集群消费。一个 Consumer Group 所标识的所有 Consumer 平均分摊消费消息。例如某个 Topic 有 9 条消息，一个 Consumer Group 有 3 个 Consumer 实例，那么在集群消费模式下每个实例平均分摊，只消费其中的 3 条消息。

### Sequential publish

顺序发布。对于指定的一个 Topic，客户端将按照一定的先后顺序发送消息。

### Sequential consumption

顺序消费。对于指定的一个 Topic，按照一定的先后顺序进行接收消息，即先发送的消息一定会先被客户端接收到。

### Message pileup

消息堆积。Producer 已经将消息发送到 订阅 服务端，但由于 Consumer 消费能力有限，未能在短时间内将所有消息正确消费掉，此时在 订阅 服务端保存着未被消费的消息，该状态即消息堆积。

### Message filtering

消息过滤。订阅者可以根据过滤条件对消息进行过滤，确保订阅者最终只接收被过滤后的数据。消息过滤在 订阅 服务端完成。

<!--end-->